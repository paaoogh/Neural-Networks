{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai as fai\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import fastai.vision.all as fv\n",
    "from torchvision.transforms import ToTensor, ToPILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(folder, img_size, batch_size):\n",
    "    \n",
    "    tfms = fv.aug_transforms(flip_vert=True, max_rotate=360, max_lighting=0.3,max_zoom=1.2,max_warp=0.2)\n",
    "    \n",
    "    data = fv.DataBlock(\n",
    "                        blocks    = (fv.ImageBlock, fv.CategoryBlock),\n",
    "                        get_items = fv.get_image_files,\n",
    "                        get_y     = lambda x: x.parent.name,\n",
    "                        splitter  = fv.GrandparentSplitter(),\n",
    "                        item_tfms = fv.Resize(img_size),\n",
    "                        batch_tfms= tfms,\n",
    "                     )\n",
    "    return data.dataloaders(folder,bs=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"flowers\", img_size=224, batch_size=128).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten servir치 para conectar las capas convolucionales con las lineales (densas)\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):#init es cuando creas un objeto siempre\n",
    "        super().__init__() #esto tambien es de cajon en todos los modulos de python\n",
    "    \n",
    "    def forward(self,x): #esta funcion lo unico que hace es pasar de convolucional a la parte lineal o densa\n",
    "        #return x.squeeze() #esto tiene un peque침o error cuando la Batch Size sea de 1: la va a quitar\n",
    "        return x.view(x.shape[0],-1) #o x.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.BatchNorm2d(3),\n",
    "    nn.Conv2d(3,32, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(32,64, kernel_size=3, stride=2, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(64,128, kernel_size=3, stride=2, padding=1),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(128,256, kernel_size=3, stride=2, padding=1),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(256,512, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Flatten(),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.Linear(512,256),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.Linear(256, data.c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 224, 224])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape #la batch de im치genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorCategory([ 47,  78,  97,  34,  96,  23,  49,  15,  97,  69,  97,   6,  29,   6,\n",
       "          73,  82,  73,  56,  44,  96,  51,  31,  35,   3,  66,   2,  63,  44,\n",
       "          85,  79,  21,  95,  46,  82,   1, 101,  59,  53,  62,  25,  69,  20,\n",
       "          98,  31,  69,  69,  11,  84,   2,  39,  38,  26,  82,   3,  90,  62,\n",
       "          31,  77,  35,  89,   7,  30,  22,  98,  93,  94,  79,  64,  97,  63,\n",
       "          82,  22,  89,   8,  96,  64,  43,   9,  50,   3,  74,  86,  29,  46,\n",
       "          66,  90,  92,  30,  69,   3,  68,  43,  36,  42,  58,  69,  46,  96,\n",
       "          49,  97,  97,  91,  61,  31,  66,  75,  25,  98,  18,   0,  66,   9,\n",
       "          62,  81,  74,  45,  52,  98,  75,  86, 101,  67,  89,  60,  70,  19,\n",
       "          26,  35]),\n",
       " torch.Size([128]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorImage([[ 0.6981,  0.2981,  0.7111,  ...,  2.1236, -0.4089,  0.3520],\n",
       "         [ 0.3114,  0.5317,  0.4605,  ...,  1.5059,  0.6413,  0.8027],\n",
       "         [-1.4082,  0.0556, -0.7916,  ...,  0.1958, -0.0925, -0.8400],\n",
       "         ...,\n",
       "         [ 0.2047, -0.0108, -0.0568,  ..., -0.1234,  0.4563, -0.4029],\n",
       "         [-1.1821,  0.2389, -0.4801,  ..., -0.9712,  0.4503,  0.4711],\n",
       "         [-0.4847,  0.7709, -0.2336,  ..., -0.0716,  0.1796,  0.4752]],\n",
       "        grad_fn=<AliasBackward>),\n",
       " torch.Size([128, 102]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x),model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorImage([[0.6678, 0.5740, 0.6707,  ..., 0.8932, 0.3992, 0.5871],\n",
       "        [0.5772, 0.6299, 0.6131,  ..., 0.8184, 0.6550, 0.6905],\n",
       "        [0.1965, 0.5139, 0.3118,  ..., 0.5488, 0.4769, 0.3015],\n",
       "        ...,\n",
       "        [0.5510, 0.4973, 0.4858,  ..., 0.4692, 0.6121, 0.4006],\n",
       "        [0.2347, 0.5594, 0.3822,  ..., 0.2746, 0.6107, 0.6156],\n",
       "        [0.3811, 0.6837, 0.4419,  ..., 0.4821, 0.5448, 0.6166]],\n",
       "       grad_fn=<AliasBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(model(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorImage([[0.0176, 0.0118, 0.0178,  ..., 0.0731, 0.0058, 0.0124],\n",
       "        [0.0103, 0.0129, 0.0120,  ..., 0.0341, 0.0144, 0.0169],\n",
       "        [0.0020, 0.0088, 0.0038,  ..., 0.0101, 0.0076, 0.0036],\n",
       "        ...,\n",
       "        [0.0099, 0.0080, 0.0076,  ..., 0.0071, 0.0128, 0.0054],\n",
       "        [0.0026, 0.0106, 0.0052,  ..., 0.0032, 0.0131, 0.0134],\n",
       "        [0.0054, 0.0188, 0.0069,  ..., 0.0081, 0.0104, 0.0140]],\n",
       "       grad_fn=<AliasBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(model(x),dim=1) #dim 1 para cada rengl칩n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorImage([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000], grad_fn=<AliasBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(model(x),dim=1).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3331, 0.1335, 0.5334],\n",
       "        [0.4596, 0.3072, 0.2332],\n",
       "        [0.2866, 0.1999, 0.5135],\n",
       "        [0.5496, 0.2319, 0.2185],\n",
       "        [0.7035, 0.0870, 0.2096]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.randn(5,3),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0001"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7035+ 0.0870+ 0.2096"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 102])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorCategory([ 47,  78,  97,  34,  96,  23,  49,  15,  97,  69,  97,   6,  29,   6,\n",
       "          73,  82,  73,  56,  44,  96,  51,  31,  35,   3,  66,   2,  63,  44,\n",
       "          85,  79,  21,  95,  46,  82,   1, 101,  59,  53,  62,  25,  69,  20,\n",
       "          98,  31,  69,  69,  11,  84,   2,  39,  38,  26,  82,   3,  90,  62,\n",
       "          31,  77,  35,  89,   7,  30,  22,  98,  93,  94,  79,  64,  97,  63,\n",
       "          82,  22,  89,   8,  96,  64,  43,   9,  50,   3,  74,  86,  29,  46,\n",
       "          66,  90,  92,  30,  69,   3,  68,  43,  36,  42,  58,  69,  46,  96,\n",
       "          49,  97,  97,  91,  61,  31,  66,  75,  25,  98,  18,   0,  66,   9,\n",
       "          62,  81,  74,  45,  52,  98,  75,  86, 101,  67,  89,  60,  70,  19,\n",
       "          26,  35]),\n",
       " torch.Size([128]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,c=yp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.zeros_like(yp) #crear tensor de zeros del mismo tama침o de yp\n",
    "z[torch.arange(bs),y] = 1 #le pongo 1s a las posiciones apropiadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorImage([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distrancia_ecuclideana(yp, y):\n",
    "    bs, c= yp.shape\n",
    "    yp_normalizado = torch.softmax(yp,dim=1)\n",
    "    z = torch.zeros_like(yp)\n",
    "    z[torch.arange(bs,device=z.device),y] = 1\n",
    "    return F.mse_loss(yp_normalizado, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.data.core.DataLoaders at 0x7fa5bd0ea0a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = fv.Learner(data,model,loss_func=distrancia_ecuclideana,metrics=fv.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.009536</td>\n",
       "      <td>0.009566</td>\n",
       "      <td>0.118343</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.009159</td>\n",
       "      <td>0.008762</td>\n",
       "      <td>0.220907</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>0.270217</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorImage([[ 0.6981,  0.2981,  0.7111,  ...,  2.1236, -0.4089,  0.3520],\n",
       "         [ 0.3114,  0.5317,  0.4605,  ...,  1.5059,  0.6413,  0.8027],\n",
       "         [-1.4082,  0.0556, -0.7916,  ...,  0.1958, -0.0925, -0.8400],\n",
       "         ...,\n",
       "         [ 0.2047, -0.0108, -0.0568,  ..., -0.1234,  0.4563, -0.4029],\n",
       "         [-1.1821,  0.2389, -0.4801,  ..., -0.9712,  0.4503,  0.4711],\n",
       "         [-0.4847,  0.7709, -0.2336,  ..., -0.0716,  0.1796,  0.4752]],\n",
       "        grad_fn=<AliasBackward>),\n",
       " TensorCategory([ 47,  78,  97,  34,  96,  23,  49,  15,  97,  69,  97,   6,  29,   6,\n",
       "          73,  82,  73,  56,  44,  96,  51,  31,  35,   3,  66,   2,  63,  44,\n",
       "          85,  79,  21,  95,  46,  82,   1, 101,  59,  53,  62,  25,  69,  20,\n",
       "          98,  31,  69,  69,  11,  84,   2,  39,  38,  26,  82,   3,  90,  62,\n",
       "          31,  77,  35,  89,   7,  30,  22,  98,  93,  94,  79,  64,  97,  63,\n",
       "          82,  22,  89,   8,  96,  64,  43,   9,  50,   3,  74,  86,  29,  46,\n",
       "          66,  90,  92,  30,  69,   3,  68,  43,  36,  42,  58,  69,  46,  96,\n",
       "          49,  97,  97,  91,  61,  31,  66,  75,  25,  98,  18,   0,  66,   9,\n",
       "          62,  81,  74,  45,  52,  98,  75,  86, 101,  67,  89,  60,  70,  19,\n",
       "          26,  35]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorImage(4.7532, grad_fn=<AliasBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(yp,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.BatchNorm2d(3),\n",
    "    nn.Conv2d(3,32, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(32,64, kernel_size=3, stride=2, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(64,128, kernel_size=3, stride=2, padding=1),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(128,256, kernel_size=3, stride=2, padding=1),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(256,512, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Flatten(),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.Linear(512,256),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.Linear(256, data.c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = fv.Learner(data,model, loss_func=F.cross_entropy,metrics=fv.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.803591</td>\n",
       "      <td>3.284229</td>\n",
       "      <td>0.211045</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.116828</td>\n",
       "      <td>2.768371</td>\n",
       "      <td>0.311637</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.696129</td>\n",
       "      <td>2.421287</td>\n",
       "      <td>0.388560</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = nn.Dropout(p=0.5)#va a matar aleatoriamente la mitad de las activaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1536, 0.4293, 0.9672, 0.8392, 0.0232, 0.2964, 0.5813, 0.6330, 0.1087,\n",
       "         0.1348]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3073, 0.8587, 1.9344, 1.6784, 0.0465, 0.5929, 0.0000, 0.0000, 0.2174,\n",
       "         0.2696]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 2., 0., 0., 2., 2., 2., 0., 0., 2.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop(x)/x #en este caso el factor es de 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): AdaptiveConcatPool2d(\n",
       "    (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "    (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "  )\n",
       "  (1): Flatten(full=False)\n",
       "  (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): Dropout(p=0.1, inplace=False)\n",
       "  (4): Linear(in_features=10, out_features=512, bias=False)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Dropout(p=0.2, inplace=False)\n",
       "  (8): Linear(in_features=512, out_features=20, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv.create_head(10,20,ps=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rant: Normalizaci칩n en el pipeline \n",
    "Disclaimer: lo siguiente es lo que **NO** tienes que hacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorImage(1., device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.one_batch()[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = fv.cnn_learner(data, fv.resnet18) #Fastai madofica data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorImage([[[[ 6.8496e-01,  5.5976e-01,  4.8874e-01,  ..., -1.1879e+00,\n",
       "           -1.1040e+00, -9.6079e-01],\n",
       "          [ 5.1974e-01,  4.7323e-01,  4.0884e-01,  ..., -1.1359e+00,\n",
       "           -1.2606e+00, -1.2288e+00],\n",
       "          [ 4.1374e-01,  3.8843e-01,  3.4905e-01,  ..., -1.1664e+00,\n",
       "           -1.2057e+00, -1.1853e+00],\n",
       "          ...,\n",
       "          [ 9.2473e-01,  9.3705e-01,  8.8014e-01,  ...,  6.7229e-01,\n",
       "            6.4242e-01,  5.3628e-01],\n",
       "          [ 9.0665e-01,  8.9364e-01,  8.6092e-01,  ...,  6.6271e-01,\n",
       "            6.5749e-01,  5.5991e-01],\n",
       "          [ 8.1143e-01,  8.0738e-01,  7.9074e-01,  ...,  6.1540e-01,\n",
       "            6.2962e-01,  6.0171e-01]],\n",
       "\n",
       "         [[ 1.4642e+00,  1.4095e+00,  1.3567e+00,  ..., -8.8660e-01,\n",
       "           -7.2954e-01, -5.3610e-01],\n",
       "          [ 1.3675e+00,  1.3188e+00,  1.2719e+00,  ..., -9.8283e-01,\n",
       "           -1.0049e+00, -9.1443e-01],\n",
       "          [ 1.2636e+00,  1.2331e+00,  1.2031e+00,  ..., -1.0795e+00,\n",
       "           -1.0837e+00, -1.0061e+00],\n",
       "          ...,\n",
       "          [ 1.1947e+00,  1.2195e+00,  1.1628e+00,  ...,  9.2469e-01,\n",
       "            8.8533e-01,  7.7343e-01],\n",
       "          [ 1.1686e+00,  1.1712e+00,  1.1437e+00,  ...,  9.0580e-01,\n",
       "            8.9879e-01,  7.9713e-01],\n",
       "          [ 1.0719e+00,  1.0795e+00,  1.0701e+00,  ...,  8.6025e-01,\n",
       "            8.7004e-01,  8.3882e-01]],\n",
       "\n",
       "         [[ 1.2103e+00,  1.1679e+00,  1.1130e+00,  ..., -8.4705e-01,\n",
       "           -6.8090e-01, -4.9217e-01],\n",
       "          [ 1.0947e+00,  1.0512e+00,  1.0035e+00,  ..., -8.7949e-01,\n",
       "           -8.8923e-01, -8.1003e-01],\n",
       "          [ 9.6932e-01,  9.4245e-01,  9.1904e-01,  ..., -9.4747e-01,\n",
       "           -9.5028e-01, -8.6684e-01],\n",
       "          ...,\n",
       "          [ 2.6400e+00,  2.6340e+00,  2.5865e+00,  ...,  2.5960e+00,\n",
       "            2.5962e+00,  2.5378e+00],\n",
       "          [ 2.6371e+00,  2.6213e+00,  2.5845e+00,  ...,  2.5815e+00,\n",
       "            2.5941e+00,  2.5546e+00],\n",
       "          [ 2.5971e+00,  2.5823e+00,  2.5437e+00,  ...,  2.5470e+00,\n",
       "            2.5738e+00,  2.5890e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2508e-01, -6.1653e-01, -6.5740e-01,  ..., -1.0370e+00,\n",
       "           -7.5552e-01, -5.7779e-01],\n",
       "          [ 6.3582e-01,  5.5249e-01, -4.5726e-02,  ..., -8.5930e-01,\n",
       "           -6.0587e-01, -5.6966e-01],\n",
       "          [ 4.4735e-01,  5.9734e-01,  7.0635e-01,  ..., -6.9274e-01,\n",
       "           -5.5369e-01, -7.3527e-01],\n",
       "          ...,\n",
       "          [-1.7832e-01, -3.4534e-01, -6.5384e-01,  ..., -1.0279e+00,\n",
       "           -1.0974e+00, -9.5829e-01],\n",
       "          [-2.2725e-01, -2.9888e-01, -6.1308e-01,  ..., -7.0801e-01,\n",
       "           -3.5138e-01, -4.3197e-01],\n",
       "          [-1.7269e-01, -1.8309e-01, -3.3745e-01,  ..., -7.6324e-01,\n",
       "           -1.9604e-01, -2.8166e-01]],\n",
       "\n",
       "         [[ 1.0297e+00,  2.5804e-01,  2.1060e-01,  ..., -4.5762e-01,\n",
       "           -3.3093e-02,  2.8332e-01],\n",
       "          [ 1.5078e+00,  1.4208e+00,  8.3166e-01,  ..., -1.4941e-01,\n",
       "            1.0062e-01,  2.5152e-01],\n",
       "          [ 1.3004e+00,  1.4537e+00,  1.5582e+00,  ...,  9.7044e-02,\n",
       "            2.0174e-01, -5.8163e-02],\n",
       "          ...,\n",
       "          [ 6.9209e-01,  5.2569e-01,  2.3429e-01,  ..., -9.6393e-02,\n",
       "           -2.0533e-01,  3.5922e-06],\n",
       "          [ 6.3472e-01,  5.5453e-01,  2.4358e-01,  ...,  1.9388e-01,\n",
       "            5.8399e-01,  4.6946e-01],\n",
       "          [ 6.8134e-01,  6.4154e-01,  4.8490e-01,  ...,  1.5779e-01,\n",
       "            7.5595e-01,  5.6925e-01]],\n",
       "\n",
       "         [[ 1.3926e+00,  6.1259e-01,  5.4274e-01,  ..., -7.2609e-02,\n",
       "            5.2346e-01,  9.5686e-01],\n",
       "          [ 1.8908e+00,  1.7849e+00,  1.2112e+00,  ...,  5.1695e-02,\n",
       "            5.6215e-01,  8.5605e-01],\n",
       "          [ 1.7521e+00,  1.8628e+00,  1.9651e+00,  ...,  2.0737e-01,\n",
       "            5.3396e-01,  4.1190e-01],\n",
       "          ...,\n",
       "          [ 5.7509e-01,  4.0780e-01,  1.4832e-01,  ...,  3.8056e-01,\n",
       "            1.9133e-01,  3.8237e-01],\n",
       "          [ 4.8815e-01,  4.0442e-01,  1.2947e-01,  ...,  6.8596e-01,\n",
       "            1.0330e+00,  8.6102e-01],\n",
       "          [ 4.9402e-01,  4.4997e-01,  3.4727e-01,  ...,  7.2563e-01,\n",
       "            1.2222e+00,  9.2031e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.5725e+00, -1.6327e+00, -1.7035e+00,  ..., -2.0553e+00,\n",
       "           -2.0650e+00, -2.0568e+00],\n",
       "          [-1.6277e+00, -1.6738e+00, -1.7254e+00,  ..., -2.0618e+00,\n",
       "           -2.0694e+00, -2.0711e+00],\n",
       "          [-1.6766e+00, -1.7154e+00, -1.7394e+00,  ..., -2.0748e+00,\n",
       "           -2.0800e+00, -2.0819e+00],\n",
       "          ...,\n",
       "          [-2.1177e+00, -2.1027e+00, -2.0926e+00,  ..., -2.0903e+00,\n",
       "           -2.1071e+00, -2.1097e+00],\n",
       "          [-2.1150e+00, -2.0904e+00, -2.0679e+00,  ..., -2.1004e+00,\n",
       "           -2.1118e+00, -2.1179e+00],\n",
       "          [-2.1155e+00, -2.0997e+00, -2.0692e+00,  ..., -2.1084e+00,\n",
       "           -2.1160e+00, -2.1179e+00]],\n",
       "\n",
       "         [[-1.0469e+00, -1.1209e+00, -1.2616e+00,  ..., -1.9618e+00,\n",
       "           -1.9713e+00, -1.9628e+00],\n",
       "          [-1.1238e+00, -1.1829e+00, -1.3059e+00,  ..., -1.9846e+00,\n",
       "           -1.9862e+00, -1.9687e+00],\n",
       "          [-1.2011e+00, -1.2331e+00, -1.3241e+00,  ..., -2.0023e+00,\n",
       "           -1.9926e+00, -1.9721e+00],\n",
       "          ...,\n",
       "          [-1.9665e+00, -1.9252e+00, -1.8962e+00,  ..., -1.9017e+00,\n",
       "           -1.9124e+00, -1.9185e+00],\n",
       "          [-1.9782e+00, -1.9352e+00, -1.8851e+00,  ..., -1.9157e+00,\n",
       "           -1.9255e+00, -1.9296e+00],\n",
       "          [-1.9922e+00, -1.9577e+00, -1.9162e+00,  ..., -1.9348e+00,\n",
       "           -1.9358e+00, -1.9175e+00]],\n",
       "\n",
       "         [[-1.1827e+00, -1.2457e+00, -1.3096e+00,  ..., -1.6900e+00,\n",
       "           -1.6984e+00, -1.6900e+00],\n",
       "          [-1.2364e+00, -1.2797e+00, -1.3214e+00,  ..., -1.7354e+00,\n",
       "           -1.7317e+00, -1.7153e+00],\n",
       "          [-1.2959e+00, -1.3169e+00, -1.3145e+00,  ..., -1.7606e+00,\n",
       "           -1.7487e+00, -1.7282e+00],\n",
       "          ...,\n",
       "          [-1.8042e+00, -1.7783e+00, -1.7634e+00,  ..., -1.7651e+00,\n",
       "           -1.7759e+00, -1.7871e+00],\n",
       "          [-1.8014e+00, -1.7731e+00, -1.7366e+00,  ..., -1.7854e+00,\n",
       "           -1.7958e+00, -1.7990e+00],\n",
       "          [-1.8020e+00, -1.7770e+00, -1.7325e+00,  ..., -1.8021e+00,\n",
       "           -1.8035e+00, -1.8000e+00]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 2.1191e+00,  2.0613e+00,  1.9950e+00,  ..., -1.3884e+00,\n",
       "           -1.2743e+00, -1.2176e+00],\n",
       "          [ 2.0600e+00,  2.0149e+00,  1.9867e+00,  ..., -1.3068e+00,\n",
       "           -1.1987e+00, -1.2237e+00],\n",
       "          [ 1.9971e+00,  1.9819e+00,  1.9581e+00,  ..., -1.2631e+00,\n",
       "           -1.2473e+00, -1.2558e+00],\n",
       "          ...,\n",
       "          [-1.2234e+00, -1.2377e+00, -1.2682e+00,  ...,  1.3415e+00,\n",
       "            1.2730e+00,  1.2472e+00],\n",
       "          [-1.2823e+00, -1.3013e+00, -1.3369e+00,  ...,  1.3383e+00,\n",
       "            1.2239e+00,  1.2153e+00],\n",
       "          [-1.3569e+00, -1.3638e+00, -1.3565e+00,  ...,  1.3867e+00,\n",
       "            1.2931e+00,  1.2336e+00]],\n",
       "\n",
       "         [[ 8.7534e-01,  8.0896e-01,  7.4223e-01,  ..., -6.7239e-01,\n",
       "           -6.1633e-01, -5.6370e-01],\n",
       "          [ 8.2349e-01,  7.6997e-01,  7.4317e-01,  ..., -6.9960e-01,\n",
       "           -6.3091e-01, -5.7169e-01],\n",
       "          [ 7.8015e-01,  7.6290e-01,  7.3855e-01,  ..., -7.1282e-01,\n",
       "           -6.1962e-01, -5.6144e-01],\n",
       "          ...,\n",
       "          [-7.0948e-01, -6.9943e-01, -6.5252e-01,  ...,  6.5502e-01,\n",
       "            7.7274e-01,  8.0158e-01],\n",
       "          [-7.0393e-01, -6.6583e-01, -6.0674e-01,  ...,  6.8206e-01,\n",
       "            8.1513e-01,  7.9239e-01],\n",
       "          [-6.7255e-01, -6.2546e-01, -6.0417e-01,  ...,  7.3764e-01,\n",
       "            8.2406e-01,  8.0157e-01]],\n",
       "\n",
       "         [[-1.6277e+00, -1.6443e+00, -1.6703e+00,  ..., -1.2294e+00,\n",
       "           -1.3092e+00, -1.3029e+00],\n",
       "          [-1.6842e+00, -1.6988e+00, -1.7180e+00,  ..., -1.2219e+00,\n",
       "           -1.3142e+00, -1.1448e+00],\n",
       "          [-1.7270e+00, -1.7355e+00, -1.7569e+00,  ..., -1.1834e+00,\n",
       "           -1.2453e+00, -1.0771e+00],\n",
       "          ...,\n",
       "          [-1.4392e+00, -1.3037e+00, -1.3017e+00,  ..., -1.4704e+00,\n",
       "           -1.4800e+00, -1.5822e+00],\n",
       "          [-1.2880e+00, -1.3002e+00, -1.4074e+00,  ..., -1.6205e+00,\n",
       "           -1.5708e+00, -1.6286e+00],\n",
       "          [-1.2927e+00, -1.3931e+00, -1.3777e+00,  ..., -1.6444e+00,\n",
       "           -1.6897e+00, -1.7081e+00]]],\n",
       "\n",
       "\n",
       "        [[[-1.9017e+00, -1.9013e+00, -1.8944e+00,  ..., -1.8910e+00,\n",
       "           -1.8801e+00, -1.8810e+00],\n",
       "          [-1.9041e+00, -1.9060e+00, -1.8906e+00,  ..., -1.8943e+00,\n",
       "           -1.8837e+00, -1.8856e+00],\n",
       "          [-1.9092e+00, -1.8859e+00, -1.8703e+00,  ..., -1.9045e+00,\n",
       "           -1.8814e+00, -1.8709e+00],\n",
       "          ...,\n",
       "          [-1.8705e+00, -1.8558e+00, -1.8273e+00,  ..., -1.8681e+00,\n",
       "           -1.8635e+00, -1.8650e+00],\n",
       "          [-1.8693e+00, -1.8470e+00, -1.8493e+00,  ..., -1.8829e+00,\n",
       "           -1.8755e+00, -1.8818e+00],\n",
       "          [-1.8696e+00, -1.8817e+00, -1.8686e+00,  ..., -1.8602e+00,\n",
       "           -1.8813e+00, -1.9166e+00]],\n",
       "\n",
       "         [[-1.6717e+00, -1.6713e+00, -1.6639e+00,  ..., -1.6967e+00,\n",
       "           -1.6852e+00, -1.6844e+00],\n",
       "          [-1.6742e+00, -1.6762e+00, -1.6598e+00,  ..., -1.7002e+00,\n",
       "           -1.6890e+00, -1.6859e+00],\n",
       "          [-1.6797e+00, -1.6548e+00, -1.6382e+00,  ..., -1.7110e+00,\n",
       "           -1.6866e+00, -1.6751e+00],\n",
       "          ...,\n",
       "          [-1.6383e+00, -1.6227e+00, -1.5923e+00,  ..., -1.6358e+00,\n",
       "           -1.6374e+00, -1.6597e+00],\n",
       "          [-1.6370e+00, -1.6132e+00, -1.6158e+00,  ..., -1.6516e+00,\n",
       "           -1.6512e+00, -1.6785e+00],\n",
       "          [-1.6374e+00, -1.6504e+00, -1.6363e+00,  ..., -1.6274e+00,\n",
       "           -1.6544e+00, -1.7009e+00]],\n",
       "\n",
       "         [[-1.4902e+00, -1.4898e+00, -1.4825e+00,  ..., -1.5105e+00,\n",
       "           -1.5101e+00, -1.5219e+00],\n",
       "          [-1.4927e+00, -1.4947e+00, -1.4785e+00,  ..., -1.5145e+00,\n",
       "           -1.5142e+00, -1.5281e+00],\n",
       "          [-1.4980e+00, -1.4737e+00, -1.4573e+00,  ..., -1.5254e+00,\n",
       "           -1.5123e+00, -1.5185e+00],\n",
       "          ...,\n",
       "          [-1.4574e+00, -1.4421e+00, -1.4123e+00,  ..., -1.4550e+00,\n",
       "           -1.4497e+00, -1.4495e+00],\n",
       "          [-1.4562e+00, -1.4328e+00, -1.4353e+00,  ..., -1.4705e+00,\n",
       "           -1.4595e+00, -1.4586e+00],\n",
       "          [-1.4566e+00, -1.4693e+00, -1.4555e+00,  ..., -1.4467e+00,\n",
       "           -1.4530e+00, -1.4568e+00]]],\n",
       "\n",
       "\n",
       "        [[[-1.1632e+00, -1.4683e+00, -1.6789e+00,  ..., -1.6351e+00,\n",
       "           -1.6107e+00, -1.5986e+00],\n",
       "          [-1.8194e-01, -5.1418e-01, -9.7356e-01,  ..., -1.6356e+00,\n",
       "           -1.6089e+00, -1.5999e+00],\n",
       "          [ 2.6278e-01,  1.3396e-01, -2.0465e-01,  ..., -1.6459e+00,\n",
       "           -1.6168e+00, -1.6055e+00],\n",
       "          ...,\n",
       "          [-1.7340e+00, -1.7252e+00, -1.7301e+00,  ..., -1.7772e+00,\n",
       "           -1.7584e+00, -1.7418e+00],\n",
       "          [-1.7268e+00, -1.7197e+00, -1.7204e+00,  ..., -1.7746e+00,\n",
       "           -1.7907e+00, -1.7642e+00],\n",
       "          [-1.7504e+00, -1.7584e+00, -1.7439e+00,  ..., -1.7247e+00,\n",
       "           -1.7443e+00, -1.7484e+00]],\n",
       "\n",
       "         [[-7.8335e-01, -1.1123e+00, -1.3517e+00,  ..., -1.0973e+00,\n",
       "           -1.0672e+00, -1.0525e+00],\n",
       "          [ 2.9373e-01, -5.0111e-02, -5.4897e-01,  ..., -1.0979e+00,\n",
       "           -1.0651e+00, -1.0541e+00],\n",
       "          [ 7.5622e-01,  6.2697e-01,  2.7393e-01,  ..., -1.1106e+00,\n",
       "           -1.0748e+00, -1.0609e+00],\n",
       "          ...,\n",
       "          [-1.1495e+00, -1.1402e+00, -1.1618e+00,  ..., -1.3224e+00,\n",
       "           -1.2704e+00, -1.2491e+00],\n",
       "          [-1.1622e+00, -1.1676e+00, -1.1790e+00,  ..., -1.3257e+00,\n",
       "           -1.3155e+00, -1.2770e+00],\n",
       "          [-1.2312e+00, -1.2571e+00, -1.2482e+00,  ..., -1.2443e+00,\n",
       "           -1.2338e+00, -1.2484e+00]],\n",
       "\n",
       "         [[-1.2706e+00, -1.4215e+00, -1.5399e+00,  ..., -1.4211e+00,\n",
       "           -1.3925e+00, -1.3642e+00],\n",
       "          [-8.2687e-01, -8.7385e-01, -1.0887e+00,  ..., -1.4215e+00,\n",
       "           -1.3889e+00, -1.3615e+00],\n",
       "          [-7.2383e-01, -5.8162e-01, -6.5107e-01,  ..., -1.4313e+00,\n",
       "           -1.3980e+00, -1.3667e+00],\n",
       "          ...,\n",
       "          [-1.3996e+00, -1.3941e+00, -1.4099e+00,  ..., -1.5152e+00,\n",
       "           -1.4677e+00, -1.4224e+00],\n",
       "          [-1.4041e+00, -1.4059e+00, -1.4124e+00,  ..., -1.5178e+00,\n",
       "           -1.5028e+00, -1.4559e+00],\n",
       "          [-1.4477e+00, -1.4655e+00, -1.4561e+00,  ..., -1.4652e+00,\n",
       "           -1.4593e+00, -1.4642e+00]]]], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = data.one_batch(); x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que s칤 hay que hacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"flowers/\", 128,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = fv.cnn_learner(data, fv.resnet18, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorImage([[[[5.8905e-01, 4.7535e-01, 3.3563e-01,  ..., 2.4043e-01,\n",
       "           4.0860e-01, 3.7871e-01],\n",
       "          [5.9370e-01, 5.3798e-01, 4.4467e-01,  ..., 3.5732e-01,\n",
       "           4.3652e-01, 4.4750e-01],\n",
       "          [5.4872e-01, 5.4318e-01, 4.7088e-01,  ..., 4.1778e-01,\n",
       "           4.5799e-01, 4.2388e-01],\n",
       "          ...,\n",
       "          [4.5593e-01, 5.3773e-01, 5.2584e-01,  ..., 4.0209e-01,\n",
       "           4.3608e-01, 4.8121e-01],\n",
       "          [4.2766e-01, 4.3637e-01, 4.0105e-01,  ..., 3.6656e-01,\n",
       "           3.8448e-01, 4.2904e-01],\n",
       "          [4.2246e-01, 4.0106e-01, 3.5437e-01,  ..., 4.1231e-01,\n",
       "           3.8813e-01, 4.0922e-01]],\n",
       "\n",
       "         [[5.5812e-01, 5.1150e-01, 4.4174e-01,  ..., 3.9598e-01,\n",
       "           5.4713e-01, 5.1951e-01],\n",
       "          [5.6958e-01, 5.5412e-01, 4.9710e-01,  ..., 4.8608e-01,\n",
       "           5.6207e-01, 5.6930e-01],\n",
       "          [5.7169e-01, 5.6273e-01, 5.0705e-01,  ..., 5.4162e-01,\n",
       "           5.7195e-01, 5.3730e-01],\n",
       "          ...,\n",
       "          [6.1911e-01, 6.8550e-01, 6.7578e-01,  ..., 4.6604e-01,\n",
       "           4.4648e-01, 4.6250e-01],\n",
       "          [6.0173e-01, 6.0922e-01, 5.8134e-01,  ..., 4.4821e-01,\n",
       "           4.1489e-01, 4.3720e-01],\n",
       "          [5.9303e-01, 5.7333e-01, 5.3830e-01,  ..., 4.9390e-01,\n",
       "           4.3524e-01, 4.3891e-01]],\n",
       "\n",
       "         [[3.1533e-01, 2.4473e-01, 1.6235e-01,  ..., 9.4335e-02,\n",
       "           2.8791e-01, 2.4544e-01],\n",
       "          [3.1684e-01, 2.8797e-01, 2.2017e-01,  ..., 2.2101e-01,\n",
       "           3.0875e-01, 3.2608e-01],\n",
       "          [3.0426e-01, 2.9422e-01, 2.3322e-01,  ..., 2.6775e-01,\n",
       "           3.0783e-01, 2.7814e-01],\n",
       "          ...,\n",
       "          [2.1482e-01, 3.4169e-01, 3.3105e-01,  ..., 1.8335e-01,\n",
       "           1.9690e-01, 2.1444e-01],\n",
       "          [1.7971e-01, 2.4167e-01, 2.1516e-01,  ..., 1.8616e-01,\n",
       "           1.7955e-01, 1.8932e-01],\n",
       "          [1.7455e-01, 1.9438e-01, 1.6046e-01,  ..., 2.5916e-01,\n",
       "           2.1731e-01, 2.2210e-01]]],\n",
       "\n",
       "\n",
       "        [[[2.5901e-01, 2.2694e-01, 2.0018e-01,  ..., 3.3030e-01,\n",
       "           3.4918e-01, 3.5743e-01],\n",
       "          [2.6437e-01, 2.2902e-01, 1.9891e-01,  ..., 3.2654e-01,\n",
       "           3.4469e-01, 3.5413e-01],\n",
       "          [2.7205e-01, 2.3734e-01, 2.0626e-01,  ..., 3.4322e-01,\n",
       "           3.5281e-01, 3.5315e-01],\n",
       "          ...,\n",
       "          [7.1514e-01, 7.2104e-01, 7.2010e-01,  ..., 1.1695e-01,\n",
       "           1.3722e-01, 1.6089e-01],\n",
       "          [7.1347e-01, 7.1237e-01, 7.1013e-01,  ..., 1.6288e-01,\n",
       "           2.0500e-01, 2.3347e-01],\n",
       "          [7.1180e-01, 7.1446e-01, 7.1920e-01,  ..., 1.9919e-01,\n",
       "           2.4600e-01, 2.6707e-01]],\n",
       "\n",
       "         [[2.8573e-01, 2.5174e-01, 2.2171e-01,  ..., 3.6608e-01,\n",
       "           3.8464e-01, 3.9201e-01],\n",
       "          [2.9092e-01, 2.5487e-01, 2.2290e-01,  ..., 3.6222e-01,\n",
       "           3.7918e-01, 3.8675e-01],\n",
       "          [2.9873e-01, 2.6408e-01, 2.3255e-01,  ..., 3.7908e-01,\n",
       "           3.8764e-01, 3.8602e-01],\n",
       "          ...,\n",
       "          [2.9025e-01, 3.0499e-01, 3.1371e-01,  ..., 1.2822e-01,\n",
       "           1.5122e-01, 1.7793e-01],\n",
       "          [2.8745e-01, 2.9264e-01, 2.9993e-01,  ..., 1.7787e-01,\n",
       "           2.2299e-01, 2.5581e-01],\n",
       "          [2.8426e-01, 2.9324e-01, 3.0564e-01,  ..., 2.2179e-01,\n",
       "           2.7204e-01, 2.9590e-01]],\n",
       "\n",
       "         [[1.4687e-01, 1.2581e-01, 1.1683e-01,  ..., 1.6614e-01,\n",
       "           1.8601e-01, 2.0183e-01],\n",
       "          [1.4821e-01, 1.2244e-01, 1.0805e-01,  ..., 1.6288e-01,\n",
       "           1.8290e-01, 2.0072e-01],\n",
       "          [1.5187e-01, 1.2382e-01, 1.0160e-01,  ..., 1.7750e-01,\n",
       "           1.9330e-01, 2.0324e-01],\n",
       "          ...,\n",
       "          [2.3053e-01, 2.3990e-01, 2.4707e-01,  ..., 4.6321e-02,\n",
       "           5.4935e-02, 7.2971e-02],\n",
       "          [2.2628e-01, 2.2234e-01, 2.2499e-01,  ..., 7.4629e-02,\n",
       "           9.5681e-02, 1.0576e-01],\n",
       "          [2.1707e-01, 2.1786e-01, 2.2675e-01,  ..., 9.2954e-02,\n",
       "           1.1556e-01, 1.1498e-01]]],\n",
       "\n",
       "\n",
       "        [[[5.8184e-02, 5.7549e-02, 5.8243e-02,  ..., 4.1211e-02,\n",
       "           4.9077e-02, 5.5884e-02],\n",
       "          [5.3816e-02, 5.3587e-02, 5.2559e-02,  ..., 3.9839e-02,\n",
       "           4.6483e-02, 5.3527e-02],\n",
       "          [5.0212e-02, 5.0230e-02, 4.5877e-02,  ..., 3.4386e-02,\n",
       "           3.6366e-02, 4.0878e-02],\n",
       "          ...,\n",
       "          [3.5325e-01, 3.3827e-01, 3.2469e-01,  ..., 2.3017e-02,\n",
       "           2.3017e-02, 2.3017e-02],\n",
       "          [3.4957e-01, 3.3727e-01, 3.2953e-01,  ..., 2.3017e-02,\n",
       "           2.2532e-02, 2.2351e-02],\n",
       "          [3.4823e-01, 3.3634e-01, 3.2977e-01,  ..., 2.0703e-02,\n",
       "           1.8976e-02, 1.8412e-02]],\n",
       "\n",
       "         [[1.8117e-01, 1.8040e-01, 1.7677e-01,  ..., 1.8074e-01,\n",
       "           1.9379e-01, 2.0429e-01],\n",
       "          [1.8701e-01, 1.8696e-01, 1.8795e-01,  ..., 1.7792e-01,\n",
       "           1.8910e-01, 1.9967e-01],\n",
       "          [1.9394e-01, 1.9391e-01, 1.9867e-01,  ..., 1.6720e-01,\n",
       "           1.7076e-01, 1.7764e-01],\n",
       "          ...,\n",
       "          [4.9586e-01, 4.8801e-01, 4.8835e-01,  ..., 2.7166e-02,\n",
       "           2.7166e-02, 2.7166e-02],\n",
       "          [4.9774e-01, 4.9641e-01, 5.0078e-01,  ..., 2.7166e-02,\n",
       "           2.7166e-02, 2.7166e-02],\n",
       "          [4.9837e-01, 4.9871e-01, 5.0326e-01,  ..., 2.5223e-02,\n",
       "           2.5426e-02, 2.5267e-02]],\n",
       "\n",
       "         [[6.3281e-03, 5.8453e-03, 3.4920e-03,  ..., 4.7461e-04,\n",
       "           2.1140e-03, 6.4005e-03],\n",
       "          [4.6920e-03, 4.3189e-03, 2.7943e-03,  ..., 3.7876e-04,\n",
       "           1.9837e-03, 6.3570e-03],\n",
       "          [3.3027e-03, 3.0229e-03, 1.8433e-03,  ..., 1.7912e-04,\n",
       "           1.3532e-03, 5.0278e-03],\n",
       "          ...,\n",
       "          [2.8579e-01, 2.7578e-01, 2.6789e-01,  ..., 5.0087e-03,\n",
       "           5.0087e-03, 5.0087e-03],\n",
       "          [2.8231e-01, 2.7490e-01, 2.7038e-01,  ..., 5.0087e-03,\n",
       "           5.0087e-03, 5.0087e-03],\n",
       "          [2.8105e-01, 2.7409e-01, 2.7018e-01,  ..., 3.6603e-03,\n",
       "           3.4088e-03, 3.3350e-03]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[5.7294e-01, 5.6649e-01, 5.5955e-01,  ..., 8.9250e-01,\n",
       "           7.5646e-01, 6.4488e-01],\n",
       "          [5.6245e-01, 5.5869e-01, 5.4097e-01,  ..., 8.8146e-01,\n",
       "           7.6436e-01, 6.5125e-01],\n",
       "          [5.5595e-01, 5.4628e-01, 5.2655e-01,  ..., 8.7911e-01,\n",
       "           7.8264e-01, 6.6227e-01],\n",
       "          ...,\n",
       "          [1.4328e-01, 1.3897e-01, 1.5258e-01,  ..., 3.2597e-01,\n",
       "           3.1635e-01, 3.0628e-01],\n",
       "          [1.5756e-01, 1.9630e-01, 2.6157e-01,  ..., 3.3232e-01,\n",
       "           3.1527e-01, 2.9912e-01],\n",
       "          [2.4483e-01, 3.6517e-01, 4.6195e-01,  ..., 3.3221e-01,\n",
       "           3.0975e-01, 2.9835e-01]],\n",
       "\n",
       "         [[3.6774e-01, 3.6012e-01, 3.5423e-01,  ..., 7.4515e-01,\n",
       "           6.0851e-01, 4.6303e-01],\n",
       "          [3.6545e-01, 3.4140e-01, 3.2404e-01,  ..., 7.5967e-01,\n",
       "           6.1753e-01, 4.7072e-01],\n",
       "          [3.4349e-01, 3.1221e-01, 2.9036e-01,  ..., 7.5611e-01,\n",
       "           6.2485e-01, 4.8547e-01],\n",
       "          ...,\n",
       "          [1.8183e-01, 1.8865e-01, 1.9136e-01,  ..., 3.5977e-01,\n",
       "           3.5903e-01, 3.5820e-01],\n",
       "          [1.9336e-01, 2.1974e-01, 2.7272e-01,  ..., 3.6307e-01,\n",
       "           3.5767e-01, 3.5107e-01],\n",
       "          [2.5473e-01, 3.5350e-01, 4.3413e-01,  ..., 3.6136e-01,\n",
       "           3.4965e-01, 3.5046e-01]],\n",
       "\n",
       "         [[5.0732e-01, 5.0023e-01, 4.9089e-01,  ..., 8.4660e-01,\n",
       "           7.0189e-01, 5.6604e-01],\n",
       "          [4.9204e-01, 4.7627e-01, 4.5642e-01,  ..., 8.5558e-01,\n",
       "           7.1005e-01, 5.7220e-01],\n",
       "          [4.7287e-01, 4.4913e-01, 4.2703e-01,  ..., 8.5131e-01,\n",
       "           7.2090e-01, 5.8514e-01],\n",
       "          ...,\n",
       "          [7.2820e-02, 7.7026e-02, 9.6978e-02,  ..., 2.2031e-01,\n",
       "           2.0712e-01, 1.9022e-01],\n",
       "          [8.7979e-02, 1.5288e-01, 2.3584e-01,  ..., 2.2701e-01,\n",
       "           2.0399e-01, 1.8472e-01],\n",
       "          [1.9539e-01, 3.2345e-01, 4.2204e-01,  ..., 2.3078e-01,\n",
       "           1.9935e-01, 1.8163e-01]]],\n",
       "\n",
       "\n",
       "        [[[5.9496e-01, 7.4143e-01, 8.9576e-01,  ..., 3.5014e-01,\n",
       "           3.4954e-01, 3.3843e-01],\n",
       "          [4.6786e-01, 5.5757e-01, 7.1566e-01,  ..., 3.5120e-01,\n",
       "           3.5952e-01, 3.5429e-01],\n",
       "          [3.9817e-01, 4.0953e-01, 4.8029e-01,  ..., 3.4485e-01,\n",
       "           3.5593e-01, 3.6002e-01],\n",
       "          ...,\n",
       "          [6.6743e-01, 6.8760e-01, 7.0704e-01,  ..., 5.2755e-01,\n",
       "           5.1728e-01, 5.1574e-01],\n",
       "          [6.5173e-01, 6.7601e-01, 7.1162e-01,  ..., 5.5022e-01,\n",
       "           5.2293e-01, 5.2054e-01],\n",
       "          [6.1415e-01, 6.3364e-01, 6.5492e-01,  ..., 5.9174e-01,\n",
       "           5.3784e-01, 5.4638e-01]],\n",
       "\n",
       "         [[5.4440e-01, 6.5457e-01, 7.5324e-01,  ..., 5.2893e-01,\n",
       "           5.2190e-01, 5.1176e-01],\n",
       "          [4.5296e-01, 5.1925e-01, 6.4652e-01,  ..., 5.3175e-01,\n",
       "           5.3234e-01, 5.2609e-01],\n",
       "          [3.9808e-01, 4.1273e-01, 4.7345e-01,  ..., 5.2407e-01,\n",
       "           5.3521e-01, 5.3414e-01],\n",
       "          ...,\n",
       "          [4.1710e-01, 4.3466e-01, 4.5169e-01,  ..., 4.0292e-01,\n",
       "           3.6867e-01, 3.5239e-01],\n",
       "          [4.1037e-01, 4.3480e-01, 4.7172e-01,  ..., 3.9556e-01,\n",
       "           3.6768e-01, 3.5431e-01],\n",
       "          [3.7704e-01, 4.0099e-01, 4.2720e-01,  ..., 4.2127e-01,\n",
       "           3.6753e-01, 3.7459e-01]],\n",
       "\n",
       "         [[5.8076e-01, 7.2959e-01, 8.9063e-01,  ..., 4.5062e-01,\n",
       "           4.4185e-01, 4.3156e-01],\n",
       "          [4.4967e-01, 5.3916e-01, 7.0504e-01,  ..., 4.5468e-01,\n",
       "           4.5229e-01, 4.4402e-01],\n",
       "          [3.7654e-01, 3.8095e-01, 4.6160e-01,  ..., 4.4678e-01,\n",
       "           4.4932e-01, 4.4438e-01],\n",
       "          ...,\n",
       "          [6.1055e-01, 6.2841e-01, 6.4489e-01,  ..., 5.3896e-01,\n",
       "           4.9710e-01, 4.8772e-01],\n",
       "          [5.9579e-01, 6.1651e-01, 6.5103e-01,  ..., 5.5503e-01,\n",
       "           5.0409e-01, 4.9736e-01],\n",
       "          [5.5103e-01, 5.7225e-01, 5.9667e-01,  ..., 5.9434e-01,\n",
       "           5.1784e-01, 5.2399e-01]]],\n",
       "\n",
       "\n",
       "        [[[7.4908e-02, 7.6345e-02, 7.7950e-02,  ..., 1.5866e-01,\n",
       "           1.6750e-01, 1.9945e-01],\n",
       "          [7.6840e-02, 7.8444e-02, 8.0067e-02,  ..., 1.7131e-01,\n",
       "           1.5055e-01, 1.7051e-01],\n",
       "          [7.8304e-02, 8.0559e-02, 8.1311e-02,  ..., 1.8036e-01,\n",
       "           1.7408e-01, 1.5573e-01],\n",
       "          ...,\n",
       "          [4.5814e-01, 4.2110e-01, 3.7388e-01,  ..., 1.5064e-01,\n",
       "           1.5262e-01, 1.4535e-01],\n",
       "          [4.4393e-01, 4.2301e-01, 3.8121e-01,  ..., 2.3786e-01,\n",
       "           2.0870e-01, 2.0122e-01],\n",
       "          [4.2860e-01, 4.1245e-01, 3.9635e-01,  ..., 3.5576e-01,\n",
       "           3.3054e-01, 2.7061e-01]],\n",
       "\n",
       "         [[7.8088e-02, 7.9544e-02, 8.1171e-02,  ..., 1.8374e-01,\n",
       "           1.9483e-01, 2.5684e-01],\n",
       "          [8.0046e-02, 8.1672e-02, 8.3317e-02,  ..., 2.0595e-01,\n",
       "           1.7500e-01, 1.9986e-01],\n",
       "          [8.1530e-02, 8.3814e-02, 8.6378e-02,  ..., 2.2494e-01,\n",
       "           2.1220e-01, 1.8096e-01],\n",
       "          ...,\n",
       "          [4.8711e-01, 4.5390e-01, 4.1327e-01,  ..., 2.1931e-01,\n",
       "           1.8734e-01, 1.6006e-01],\n",
       "          [4.7447e-01, 4.5461e-01, 4.2004e-01,  ..., 3.1601e-01,\n",
       "           2.6953e-01, 2.3031e-01],\n",
       "          [4.6812e-01, 4.5095e-01, 4.3282e-01,  ..., 4.2433e-01,\n",
       "           3.9700e-01, 3.1491e-01]],\n",
       "\n",
       "         [[5.9677e-02, 6.1011e-02, 6.2504e-02,  ..., 5.1553e-02,\n",
       "           4.3029e-02, 5.1827e-02],\n",
       "          [6.1471e-02, 6.2964e-02, 6.4474e-02,  ..., 7.7190e-02,\n",
       "           4.2819e-02, 4.5470e-02],\n",
       "          [6.2833e-02, 6.4932e-02, 6.6461e-02,  ..., 9.2403e-02,\n",
       "           6.6330e-02, 4.7737e-02],\n",
       "          ...,\n",
       "          [8.8658e-01, 8.2541e-01, 7.0321e-01,  ..., 1.3168e-01,\n",
       "           1.0388e-01, 1.8798e-01],\n",
       "          [8.8715e-01, 8.5423e-01, 7.4660e-01,  ..., 3.9014e-01,\n",
       "           2.6359e-01, 3.2911e-01],\n",
       "          [8.6844e-01, 8.4999e-01, 8.1104e-01,  ..., 7.0937e-01,\n",
       "           6.3511e-01, 5.4519e-01]]]], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = data.one_batch(); x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizando y desnormalizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv.imagenet_stats #por estos datos esperan los resnet normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(nn.Module):\n",
    "    def __init__(self, mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]): \n",
    "        super().__init__()\n",
    "        self.mean = torch.tensor(mean)[None,:,None,None]\n",
    "        self.std = torch.tensor(std)[None,:,None,None]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        m = self.mean.to(x)\n",
    "        s = self.std.to(x)\n",
    "        return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ -0.0172,  -1.7057,  -2.5804,  ...,  -1.1515,  -1.2079,   6.6562],\n",
       "          [ -0.8360,  -5.5545,   0.4247,  ..., -10.4694,  -7.0180,  -6.8103],\n",
       "          [ -2.3168,  -0.9566,  -0.3995,  ...,   4.5261,  -1.8944,  -3.7446],\n",
       "          ...,\n",
       "          [ -3.9944,  -7.7687,   2.2836,  ...,   0.6829,  -1.6392,  -1.0009],\n",
       "          [  1.2091,  -6.4376,  -3.4287,  ...,  -0.5127,   0.4010,  -0.1861],\n",
       "          [ -6.3290,   6.6867,  -2.6729,  ..., -11.4198,  -8.1186,  -9.0158]],\n",
       "\n",
       "         [[ -9.3681,  -1.3645,   1.4513,  ...,  -1.2663,  -5.8293,   1.8533],\n",
       "          [  2.7708,  -7.9702,  -6.9271,  ...,  -8.7777,  -1.0926,  -2.9316],\n",
       "          [ -2.9826,  -7.5074,   4.3988,  ...,  -0.0720,  -8.3963,   2.1120],\n",
       "          ...,\n",
       "          [ -6.6603,  -2.7246,  -5.6108,  ...,  -5.4349,  -4.7074,   3.3870],\n",
       "          [ -1.5184,  -6.9386,  -7.3731,  ...,  -2.6532,  -4.3538,  -7.6216],\n",
       "          [ -9.6578,  -7.6979,   1.5624,  ...,  -6.3831,   7.4009,  -5.9192]],\n",
       "\n",
       "         [[ -2.3664,  -5.0943,  -3.3881,  ...,   2.8837,  -3.8112,   5.9115],\n",
       "          [ -3.5324,  -3.3416,   0.6928,  ...,  -9.9215,   1.4628,  -7.5634],\n",
       "          [ -0.1810,   3.5869,   6.3046,  ...,  -3.4873,  -0.3632,  -9.9559],\n",
       "          ...,\n",
       "          [  3.6358,  -3.4552,  -2.7043,  ...,  -3.5231,  -4.8486,  -0.8620],\n",
       "          [ -3.1097,   1.8300,  -2.6231,  ...,   4.8385,   4.8485,  10.8162],\n",
       "          [ -4.0757,  -5.8683,  -1.5483,  ...,   4.7451,   3.3429,  -2.9490]]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(torch.randn(1,3,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = fv.cnn_learner(data,fv.resnet18, normalize=False)\n",
    "learn.model = nn.Sequential(Normalizer(),learn.model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
